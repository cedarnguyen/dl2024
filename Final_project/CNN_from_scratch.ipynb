{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math"
      ],
      "metadata": {
        "id": "FYC1ol5DyYkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLayer:\n",
        "    def __init__(self, kernel):\n",
        "        self.kernel = kernel\n",
        "        self.kernel_height = len(kernel)\n",
        "        self.kernel_width = len(kernel[0])\n",
        "\n",
        "    def forward(self, image):\n",
        "        self.image = image\n",
        "        self.output = self.convolve2d(self.image, self.kernel)\n",
        "        return self.output\n",
        "\n",
        "    def convolve2d(self, image, kernel):\n",
        "        image_height = len(image)\n",
        "        image_width = len(image[0])\n",
        "        output_height = image_height - self.kernel_height + 1\n",
        "        output_width = image_width - self.kernel_width + 1\n",
        "\n",
        "        output = [[0.0 for _ in range(output_width)] for _ in range(output_height)]\n",
        "\n",
        "        for i in range(output_height):\n",
        "            for j in range(output_width):\n",
        "                output[i][j] = sum(\n",
        "                    image[i + m][j + n] * kernel[m][n]\n",
        "                    for m in range(self.kernel_height)\n",
        "                    for n in range(self.kernel_width)\n",
        "                )\n",
        "\n",
        "        return output\n",
        "\n",
        "    def backward(self, d_out, learning_rate):\n",
        "        d_kernel = [[0.0 for _ in range(self.kernel_width)] for _ in range(self.kernel_height)]\n",
        "        d_image = [[0.0 for _ in range(len(self.image[0]))] for _ in range(len(self.image))]\n",
        "\n",
        "        for i in range(len(d_out)):\n",
        "            for j in range(len(d_out[0])):\n",
        "                for m in range(self.kernel_height):\n",
        "                    for n in range(self.kernel_width):\n",
        "                        d_kernel[m][n] += self.image[i + m][j + n] * d_out[i][j]\n",
        "                        d_image[i + m][j + n] += self.kernel[m][n] * d_out[i][j]\n",
        "\n",
        "        self.kernel = [\n",
        "            [\n",
        "                self.kernel[i][j] - learning_rate * d_kernel[i][j]\n",
        "                for j in range(self.kernel_width)\n",
        "            ]\n",
        "            for i in range(self.kernel_height)\n",
        "        ]\n",
        "\n",
        "        return d_image"
      ],
      "metadata": {
        "id": "ahEfII6rl-tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    def forward(self, feature_map):\n",
        "        self.feature_map = feature_map\n",
        "        self.output = [[max(0.0, val) for val in row] for row in feature_map]\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d_out):\n",
        "        d_feature_map = [\n",
        "            [\n",
        "                d_out[i][j] if self.feature_map[i][j] > 0 else 0.0\n",
        "                for j in range(len(d_out[0]))\n",
        "            ]\n",
        "            for i in range(len(d_out))\n",
        "        ]\n",
        "        return d_feature_map"
      ],
      "metadata": {
        "id": "1122MxP3l-wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPooling:\n",
        "    def __init__(self, size=2, stride=2):\n",
        "        self.size = size\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, feature_map):\n",
        "        self.feature_map = feature_map\n",
        "        self.output_height = (len(feature_map) - self.size) // self.stride + 1\n",
        "        self.output_width = (len(feature_map[0]) - self.size) // self.stride + 1\n",
        "\n",
        "        self.output = [\n",
        "            [\n",
        "                max(\n",
        "                    feature_map[i * self.stride + m][j * self.stride + n]\n",
        "                    for m in range(self.size)\n",
        "                    for n in range(self.size)\n",
        "                )\n",
        "                for j in range(self.output_width)\n",
        "            ]\n",
        "            for i in range(self.output_height)\n",
        "        ]\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d_out):\n",
        "        d_feature_map = [[0.0 for _ in range(len(self.feature_map[0]))] for _ in range(len(self.feature_map))]\n",
        "\n",
        "        for i in range(self.output_height):\n",
        "            for j in range(self.output_width):\n",
        "                start_i = i * self.stride\n",
        "                start_j = j * self.stride\n",
        "                pool = [\n",
        "                    [self.feature_map[start_i + m][start_j + n] for n in range(self.size)]\n",
        "                    for m in range(self.size)\n",
        "                ]\n",
        "                max_value = max(max(row) for row in pool)\n",
        "                for m in range(self.size):\n",
        "                    for n in range(self.size):\n",
        "                        if self.feature_map[start_i + m][start_j + n] == max_value:\n",
        "                            d_feature_map[start_i + m][start_j + n] = d_out[i][j]\n",
        "\n",
        "        return d_feature_map"
      ],
      "metadata": {
        "id": "G8oVKeyZl--f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnectedLayer:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        import random\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.weights = [\n",
        "            [random.uniform(-0.1, 0.1) for _ in range(input_size)]\n",
        "            for _ in range(output_size)\n",
        "        ]\n",
        "        self.bias = [0.0 for _ in range(output_size)]\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.output = [\n",
        "            sum(self.weights[i][j] * inputs[j] for j in range(self.input_size)) + self.bias[i]\n",
        "            for i in range(self.output_size)\n",
        "        ]\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d_out, learning_rate):\n",
        "        d_weights = [\n",
        "            [d_out[i] * self.inputs[j] for j in range(self.input_size)]\n",
        "            for i in range(self.output_size)\n",
        "        ]\n",
        "        d_bias = [d_out[i] for i in range(self.output_size)]\n",
        "        d_inputs = [\n",
        "            sum(self.weights[i][j] * d_out[i] for i in range(self.output_size))\n",
        "            for j in range(self.input_size)\n",
        "        ]\n",
        "\n",
        "        self.weights = [\n",
        "            [\n",
        "                self.weights[i][j] - learning_rate * d_weights[i][j]\n",
        "                for j in range(self.input_size)\n",
        "            ]\n",
        "            for i in range(self.output_size)\n",
        "        ]\n",
        "        self.bias = [\n",
        "            self.bias[i] - learning_rate * d_bias[i]\n",
        "            for i in range(self.output_size)\n",
        "        ]\n",
        "\n",
        "        return d_inputs"
      ],
      "metadata": {
        "id": "RlhV8Ohzl_A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "    def forward(self, x):\n",
        "        exp_x = [math.exp(val - max(x)) for val in x]\n",
        "        sum_exp_x = sum(exp_x)\n",
        "        self.output = [val / sum_exp_x for val in exp_x]\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, d_out):\n",
        "        d_inputs = [\n",
        "            d_out[i] * self.output[i] * (1 - self.output[i])\n",
        "            - sum(d_out[j] * self.output[j] for j in range(len(d_out)) if j != i)\n",
        "            for i in range(len(d_out))\n",
        "        ]\n",
        "        return d_inputs"
      ],
      "metadata": {
        "id": "9Y0E0uXamOY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN:\n",
        "    def __init__(self, conv_kernel, fc_input_size, fc_output_size):\n",
        "        self.conv = ConvLayer(conv_kernel)\n",
        "        self.relu = ReLU()\n",
        "        self.pool = MaxPooling()\n",
        "        self.fc = FullyConnectedLayer(fc_input_size, fc_output_size)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def forward(self, image):\n",
        "        conv_out = self.conv.forward(image)\n",
        "        relu_out = self.relu.forward(conv_out)\n",
        "        pool_out = self.pool.forward(relu_out)\n",
        "\n",
        "\n",
        "        flat_out = [pixel for row in pool_out for pixel in row]\n",
        "        fc_out = self.fc.forward(flat_out)\n",
        "        softmax_out = self.softmax.forward(fc_out)\n",
        "        return softmax_out\n",
        "\n",
        "    def backward(self, d_out, learning_rate):\n",
        "        d_fc = self.fc.backward(d_out, learning_rate)\n",
        "\n",
        "\n",
        "        d_pool = [\n",
        "            d_fc[i * self.pool.output_width:(i + 1) * self.pool.output_width]\n",
        "            for i in range(self.pool.output_height)\n",
        "        ]\n",
        "\n",
        "        d_relu = self.pool.backward(d_pool)\n",
        "        d_conv = self.relu.backward(d_relu)\n",
        "        self.conv.backward(d_conv, learning_rate)\n",
        "\n",
        "    def train(self, images, labels, epochs, learning_rate):\n",
        "\n",
        "        sample_flattened_image = [pixel for row in self.pool.forward(self.relu.forward(self.conv.forward(images[0]))) for pixel in row]\n",
        "        print(f\"FullyConnectedLayer.forward: sample_flattened_image length = {len(sample_flattened_image)}, input_size = {self.fc.input_size}\")\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "            for image, label in zip(images, labels):\n",
        "                pred = self.forward(image)\n",
        "                d_out = [pred[i] - (1 if i == label else 0) for i in range(len(pred))]\n",
        "                self.backward(d_out, learning_rate)\n",
        "\n",
        "    def predict(self, image):\n",
        "        return self.forward(image)"
      ],
      "metadata": {
        "id": "Xvw7OfqMmObX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPoujlqzpWjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e847cdee-3174-402b-9579-8f62f4ac0fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before preprocessing - X length: 70000 y length: 70000\n",
            "After preprocessing - X length: 70000 y length: 70000\n",
            "FullyConnectedLayer.forward: sample_flattened_image length = 169, input_size = 169\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Accuracy: 90.86428571428571%\n"
          ]
        }
      ],
      "source": [
        "def load_mnist():\n",
        "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "    if hasattr(X, 'values'):\n",
        "        X = X.values.tolist()\n",
        "    else:\n",
        "        X = X.tolist()\n",
        "\n",
        "    if hasattr(y, 'values'):\n",
        "        y = y.values.tolist()\n",
        "    else:\n",
        "        y = y.tolist()\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def preprocess_mnist(X, y):\n",
        "\n",
        "    X = [\n",
        "        [image[i * 28:(i + 1) * 28] for i in range(28)]\n",
        "        for image in [[pixel / 255.0 for pixel in img] for img in X]\n",
        "    ]\n",
        "    y = [int(label) for label in y]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "X, y = load_mnist()\n",
        "print(\"Before preprocessing - X length:\", len(X), \"y length:\", len(y))\n",
        "X, y = preprocess_mnist(X, y)\n",
        "print(\"After preprocessing - X length:\", len(X), \"y length:\", len(y))\n",
        "\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "conv_kernel = [\n",
        "    [1, 0, -1],\n",
        "    [1, 0, -1],\n",
        "    [1, 0, -1]\n",
        "]\n",
        "\n",
        "\n",
        "cnn = CNN(conv_kernel, fc_input_size=13 * 13, fc_output_size=10)\n",
        "\n",
        "\n",
        "cnn.train(train_images, train_labels, epochs=10, learning_rate=0.01)\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = len(test_images)\n",
        "for image, label in zip(test_images, test_labels):\n",
        "    prediction = cnn.predict(image)\n",
        "    if prediction.index(max(prediction)) == label:\n",
        "\n",
        "        correct += 1\n",
        "\n",
        "print(f\"Accuracy: {correct / total * 100}%\")\n"
      ]
    }
  ]
}